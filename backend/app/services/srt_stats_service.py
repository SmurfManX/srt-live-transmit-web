"""
SRT Statistics Service - Real-time SRT connection and stream statistics
"""
import csv
import json
import os
import re
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import threading

# Cache for SRT stats
_srt_stats_cache: Dict[str, dict] = {}
_stats_lock = threading.Lock()


def parse_srt_stats_csv(stats_file: Path) -> Optional[dict]:
    """
    Parse SRT statistics from CSV file generated by srt-live-transmit

    CSV columns (from srt-live-transmit -statspf:csv):
    Time,SocketID,pktFlowWindow,pktCongestionWindow,pktFlightSize,
    msRTT,mbpsBandwidth,mbpsMaxBW,pktSent,pktSndLoss,pktSndDrop,
    pktRetrans,byteSent,byteSndDrop,mbpsSendRate,usPktSndPeriod,
    pktRecv,pktRcvLoss,pktRcvDrop,pktRcvRetrans,pktRcvBelated,
    byteRecv,byteRcvLoss,byteRcvDrop,mbpsRecvRate,pktReorderTolerance,
    pktRcvFilterExtra,pktRcvFilterSupply,pktRcvFilterLoss
    """
    if not stats_file.exists():
        return None

    try:
        with open(stats_file, 'r') as f:
            lines = f.readlines()

        if len(lines) < 2:
            return None

        # Get header and last data line
        header = lines[0].strip().split(',')
        last_line = lines[-1].strip().split(',')

        if len(header) != len(last_line):
            return None

        stats = dict(zip(header, last_line))

        # Convert to proper types
        return {
            "timestamp": stats.get("Time", ""),
            "socket_id": int(stats.get("SocketID", 0)),
            "rtt_ms": float(stats.get("msRTT", 0)),
            "bandwidth_mbps": float(stats.get("mbpsBandwidth", 0)),
            "max_bandwidth_mbps": float(stats.get("mbpsMaxBW", 0)),
            "send_rate_mbps": float(stats.get("mbpsSendRate", 0)),
            "recv_rate_mbps": float(stats.get("mbpsRecvRate", 0)),
            "packets_sent": int(stats.get("pktSent", 0)),
            "packets_received": int(stats.get("pktRecv", 0)),
            "packets_lost_send": int(stats.get("pktSndLoss", 0)),
            "packets_lost_recv": int(stats.get("pktRcvLoss", 0)),
            "packets_dropped_send": int(stats.get("pktSndDrop", 0)),
            "packets_dropped_recv": int(stats.get("pktRcvDrop", 0)),
            "packets_retransmitted": int(stats.get("pktRetrans", 0)),
            "bytes_sent": int(stats.get("byteSent", 0)),
            "bytes_received": int(stats.get("byteRecv", 0)),
            "flight_size": int(stats.get("pktFlightSize", 0)),
            "congestion_window": int(stats.get("pktCongestionWindow", 0)),
        }
    except Exception as e:
        print(f"Error parsing SRT stats CSV: {e}")
        return None


def parse_srt_stats_json(stats_file: Path) -> Optional[dict]:
    """Parse SRT statistics from JSON file"""
    if not stats_file.exists():
        return None

    try:
        # Read last line (each stats update is a JSON line)
        with open(stats_file, 'r') as f:
            lines = f.readlines()

        if not lines:
            return None

        # Get last non-empty line
        for line in reversed(lines):
            line = line.strip()
            if line:
                return json.loads(line)

        return None
    except Exception as e:
        print(f"Error parsing SRT stats JSON: {e}")
        return None


def get_srt_connections() -> List[dict]:
    """
    Get active SRT connections using ss command
    Returns list of connections with remote addresses
    """
    connections = []

    try:
        # Use ss to find SRT connections (UDP sockets on SRT ports)
        result = subprocess.run(
            ["ss", "-unap"],
            capture_output=True,
            text=True,
            timeout=5
        )

        print(f"[DEBUG] ss -unap output:\n{result.stdout}")

        if result.returncode != 0:
            return connections

        for line in result.stdout.split('\n'):
            # Look for srt-live-transmit connections
            if 'srt-live-transmit' in line:
                parts = line.split()
                print(f"[DEBUG] ss line parts: {parts}")
                if len(parts) >= 5:
                    local_addr = parts[4] if len(parts) > 4 else ""
                    peer_addr = parts[5] if len(parts) > 5 else ""

                    # Extract PID
                    pid_match = re.search(r'pid=(\d+)', line)
                    pid = int(pid_match.group(1)) if pid_match else None

                    connections.append({
                        "local_address": local_addr,
                        "remote_address": peer_addr,
                        "pid": pid,
                        "state": "ESTAB" if peer_addr and peer_addr != "*:*" else "LISTEN"
                    })
    except Exception as e:
        print(f"Error getting SRT connections: {e}")

    # Also try lsof as backup method
    try:
        result = subprocess.run(
            ["lsof", "-i", "UDP", "-n", "-P"],
            capture_output=True,
            text=True,
            timeout=5
        )

        for line in result.stdout.split('\n'):
            if 'srt-live' in line:
                print(f"[DEBUG] lsof line: {line}")
                # Parse lsof output: COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
                parts = line.split()
                if len(parts) >= 9:
                    pid = int(parts[1]) if parts[1].isdigit() else None
                    name = parts[-1]  # Last column is NAME (local->remote or just local)

                    if '->' in name:
                        # Format: local->remote
                        local_remote = name.split('->')
                        local_addr = local_remote[0]
                        remote_addr = local_remote[1] if len(local_remote) > 1 else ""

                        # Check if this connection is not already in list
                        existing = [c for c in connections if c.get("pid") == pid and c.get("local_address") == local_addr]
                        if not existing and remote_addr:
                            connections.append({
                                "local_address": local_addr,
                                "remote_address": remote_addr,
                                "pid": pid,
                                "state": "ESTAB"
                            })
    except Exception as e:
        print(f"Error getting connections via lsof: {e}")

    return connections


def get_process_connections(pid: int) -> List[dict]:
    """Get all connections for a specific process PID"""
    connections = []

    try:
        result = subprocess.run(
            ["ss", "-unap", f"pid={pid}"],
            capture_output=True,
            text=True,
            timeout=5
        )

        for line in result.stdout.split('\n'):
            if line.strip() and not line.startswith('State'):
                parts = line.split()
                if len(parts) >= 5:
                    connections.append({
                        "local_address": parts[4] if len(parts) > 4 else "",
                        "remote_address": parts[5] if len(parts) > 5 else "",
                    })
    except Exception as e:
        print(f"Error getting process connections: {e}")

    return connections


def parse_srt_log_connections(log_file: Path) -> List[dict]:
    """
    Parse SRT log file for connection events
    Returns list of connection events with timestamps and remote addresses
    """
    events = []

    if not log_file.exists():
        return events

    try:
        with open(log_file, 'r') as f:
            for line in f:
                # Look for connection events
                # Format varies but typically includes IP:port

                # Connected event
                if 'accepted' in line.lower() or 'connected' in line.lower():
                    # Try to extract IP address
                    ip_match = re.search(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d+)', line)
                    if ip_match:
                        events.append({
                            "type": "connected",
                            "remote_ip": ip_match.group(1),
                            "remote_port": int(ip_match.group(2)),
                            "timestamp": extract_timestamp(line),
                            "raw": line.strip()
                        })

                # Disconnected event
                elif 'closed' in line.lower() or 'disconnected' in line.lower():
                    ip_match = re.search(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d+)', line)
                    if ip_match:
                        events.append({
                            "type": "disconnected",
                            "remote_ip": ip_match.group(1),
                            "remote_port": int(ip_match.group(2)),
                            "timestamp": extract_timestamp(line),
                            "raw": line.strip()
                        })
    except Exception as e:
        print(f"Error parsing SRT log: {e}")

    return events


def extract_timestamp(line: str) -> Optional[str]:
    """Extract timestamp from log line"""
    # Common timestamp formats
    patterns = [
        r'(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2})',
        r'(\d{2}:\d{2}:\d{2}\.\d+)',
    ]

    for pattern in patterns:
        match = re.search(pattern, line)
        if match:
            return match.group(1)

    return None


def get_channel_srt_stats(channel_name: str, stats_file: Path, log_file: Optional[Path] = None) -> dict:
    """
    Get comprehensive SRT statistics for a channel

    Returns:
        Dictionary with SRT stats, connection info, and events
    """
    result = {
        "channel_name": channel_name,
        "timestamp": datetime.now().isoformat(),
        "srt_stats": None,
        "connections": [],
        "connection_events": [],
        "status": "unknown"
    }

    # Parse stats file (try JSON first, then CSV)
    json_file = stats_file.with_suffix('.json')
    if json_file.exists():
        result["srt_stats"] = parse_srt_stats_json(json_file)
    elif stats_file.exists():
        result["srt_stats"] = parse_srt_stats_csv(stats_file)

    # Parse log file for connection events
    if log_file and log_file.exists():
        result["connection_events"] = parse_srt_log_connections(log_file)

        # Get last connected clients from events
        connected_clients = {}
        for event in result["connection_events"]:
            client_key = f"{event['remote_ip']}:{event['remote_port']}"
            if event["type"] == "connected":
                connected_clients[client_key] = event
            elif event["type"] == "disconnected":
                connected_clients.pop(client_key, None)

        result["active_clients"] = list(connected_clients.values())

    # Determine status
    if result["srt_stats"]:
        stats = result["srt_stats"]
        if stats.get("recv_rate_mbps", 0) > 0 or stats.get("send_rate_mbps", 0) > 0:
            result["status"] = "streaming"
        else:
            result["status"] = "connected"
    else:
        result["status"] = "no_data"

    return result


def get_all_channels_srt_stats(channels: List[dict]) -> Dict[str, dict]:
    """Get SRT statistics for all channels"""
    all_stats = {}

    for channel in channels:
        channel_name = channel.get("channel_name", "")
        stats_file = channel.get("stats_file")

        if stats_file:
            stats_path = Path(stats_file)
            log_path = Path(f"logs/{channel_name}.log")

            all_stats[channel_name] = get_channel_srt_stats(
                channel_name,
                stats_path,
                log_path if log_path.exists() else None
            )

    return all_stats


def get_combined_channel_info(channel: dict) -> dict:
    """
    Get combined channel information:
    - Basic channel config
    - SRT statistics (bitrate, RTT, packet loss)
    - Media info (resolution, codec, fps) from ffprobe
    - Connection info (remote clients)
    """
    from .stream_analyzer import analyze_stream_sync

    channel_name = channel.get("channel_name", "")

    result = {
        "channel_name": channel_name,
        "status": channel.get("status", "stopped"),
        "pid": channel.get("pid"),
        "pids": channel.get("pids", []),
        "start_date": channel.get("start_date"),
        "timestamp": datetime.now().isoformat(),

        # Input/Output config
        "input": {
            "protocol": channel.get("input_protocol", "srt"),
            "ip": channel.get("input_ip", "0.0.0.0"),
            "port": channel.get("input_port"),
            "mode": channel.get("input_mode", "listener"),
        },
        "output": {
            "protocol": channel.get("output_protocol", "srt"),
            "port": channel.get("output_port"),
            "mode": channel.get("mode", "listener"),
        },

        # Stats placeholders
        "srt_stats": None,
        "media_info": None,
        "connections": [],
    }

    if channel.get("status") != "running":
        return result

    # Get SRT stats
    stats_file = channel.get("stats_file")
    if stats_file:
        stats_path = Path(stats_file)
        if stats_path.exists():
            result["srt_stats"] = parse_srt_stats_csv(stats_path)

    # Get media info via ffprobe
    try:
        media_info = analyze_stream_sync(channel)
        if media_info.get("success"):
            result["media_info"] = {
                "format": media_info.get("format"),
                "total_bitrate_mbps": media_info.get("total_bitrate_mbps"),
                "video": media_info.get("video_streams", []),
                "audio": media_info.get("audio_streams", []),
            }
    except Exception as e:
        result["media_info"] = {"error": str(e)}

    # Get active connections for this process
    pids = channel.get("pids", [])
    if not pids and channel.get("pid"):
        pids = [channel.get("pid")]

    for pid in pids:
        if pid:
            conns = get_process_connections(pid)
            result["connections"].extend(conns)

    return result
